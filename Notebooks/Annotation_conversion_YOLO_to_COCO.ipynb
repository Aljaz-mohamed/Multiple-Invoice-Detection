{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Annotation Conversion from YOLO to COCO"
      ],
      "metadata": {
        "id": "D7ufaQXl_I6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MMDEtection toolbox of openMMLab framework requires the annotation files to be in MMCOCO-Detection format. This note book contains code to do that conversion."
      ],
      "metadata": {
        "id": "EV8i0r-4_OOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount google drive to access data stored."
      ],
      "metadata": {
        "id": "k4LlrWBi_oA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBHLPQJD1XKO",
        "outputId": "5b8dcd26-ecef-4182-919c-3aad7830e1a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import necessary libraries"
      ],
      "metadata": {
        "id": "Ahtb62ax_0T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "pb_woYbI_4Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set path for each dataset folders"
      ],
      "metadata": {
        "id": "KeG6icU4__i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_1/train/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_1/train/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_1/train/images'\n"
      ],
      "metadata": {
        "id": "-5j5zC5fAQiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_2/train/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_2/train/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_2/train/images'\n"
      ],
      "metadata": {
        "id": "r2tbr9nsAUk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_3/train/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_3/train/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_3/train/images'\n"
      ],
      "metadata": {
        "id": "1J08mStsAX4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_4/train/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_4/train/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_4/train/images'\n"
      ],
      "metadata": {
        "id": "mNwXS2GBAaKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_1/test/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_1/test/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_1/test/images'\n"
      ],
      "metadata": {
        "id": "9_fSkNnPA4o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_2/test/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_2/test/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_2/test/images'\n"
      ],
      "metadata": {
        "id": "EfiJAiKsA6uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_3/test/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_3/test/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_3/test/images'\n"
      ],
      "metadata": {
        "id": "LmdrPvS-A9A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_4/test/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_4/test/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_4/test/images'\n"
      ],
      "metadata": {
        "id": "a3l_fLA6AEEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_1/val/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_1/val/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_1/val/images'\n"
      ],
      "metadata": {
        "id": "3CBVi3unBDUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_2/val/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_2/val/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_2/val/images'\n"
      ],
      "metadata": {
        "id": "LL6t9OC6BF5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_3/val/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_3/val/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_3/val/images'\n"
      ],
      "metadata": {
        "id": "XHcmDc4xBH_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_4/val/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_4/val/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset3/2024-07-07_5-Fold_Cross-val/split_4/val/images'\n"
      ],
      "metadata": {
        "id": "2WwtRBteAEZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to create an MMCOCO-Detection annotation file from each yolo annotation files in annotation folder"
      ],
      "metadata": {
        "id": "0Npjp3GXBNXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the categories for the COCO dataset\n",
        "categories = [\n",
        "    {\"id\": 1, \"name\": \"invoice\"}\n",
        "]\n",
        "\n",
        "# Initialize the COCO dataset dictionary\n",
        "coco_dataset = {\n",
        "    \"info\": {},\n",
        "    \"licenses\": [],\n",
        "    \"categories\": categories,\n",
        "    \"images\": [],\n",
        "    \"annotations\": []\n",
        "}\n",
        "\n",
        "# Initialize a counter for image IDs\n",
        "image_id_counter = 1\n",
        "\n",
        "\n",
        "# Loop through the images in the input image directory\n",
        "for image_file in os.listdir(image_dir):\n",
        "    image_path = os.path.join(image_dir, image_file)\n",
        "    image = Image.open(image_path)\n",
        "    width, height = image.size\n",
        "\n",
        "    # Use the counter as the image ID\n",
        "    image_id = image_id_counter\n",
        "    image_id_counter += 1\n",
        "\n",
        "    # Add the image to the COCO dataset\n",
        "    image_dict = {\n",
        "        \"id\": image_id,\n",
        "        \"width\": width,\n",
        "        \"height\": height,\n",
        "        \"file_name\": image_file\n",
        "    }\n",
        "    coco_dataset[\"images\"].append(image_dict)\n",
        "\n",
        "    # Load the bounding box annotations for the image\n",
        "    annotation_file = os.path.join(annotation_dir, f'{image_file.split(\".jpg\")[0]}.txt')\n",
        "    with open(annotation_file) as f:\n",
        "        annotations = f.readlines()\n",
        "\n",
        "    # Loop through the annotations and add them to the COCO dataset\n",
        "    for ann in annotations:\n",
        "        parts = ann.strip().split()\n",
        "        category_id = int(float(parts[0])) + 1  # Extract and convert category ID to int, then add 1\n",
        "        x, y, w, h = map(float, parts[1:])  # Extract bounding box coordinates and convert to float\n",
        "\n",
        "        #x, y, w, h = map(float, ann.strip().split()[1:])\n",
        "        x_min, y_min = int((x - w / 2) * width), int((y - h / 2) * height)\n",
        "        x_max, y_max = int((x + w / 2) * width), int((y + h / 2) * height)\n",
        "        ann_dict = {\n",
        "            \"id\": len(coco_dataset[\"annotations\"]),\n",
        "            \"image_id\": image_id,\n",
        "            \"category_id\": category_id,\n",
        "            \"bbox\": [x_min, y_min, x_max - x_min, y_max - y_min],\n",
        "            \"area\": (x_max - x_min) * (y_max - y_min),\n",
        "            \"iscrowd\": 0\n",
        "        }\n",
        "        coco_dataset[\"annotations\"].append(ann_dict)\n",
        "\n",
        "# Save the COCO dataset to a JSON file\n",
        "with open(os.path.join(output_dir, 'annotations.json'), 'w') as f:\n",
        "    json.dump(coco_dataset, f)\n"
      ],
      "metadata": {
        "id": "HsfQp6RRbXoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Experiment Code"
      ],
      "metadata": {
        "id": "uj_UWnpQBd_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLO to COCO annotation conversion"
      ],
      "metadata": {
        "id": "gqCct4jqbKTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Set the paths for the input image directory and annotation directory\n",
        "image_dir = '/content/drive/MyDrive/Combined Dataset2/train/images'\n",
        "annotation_dir = '/content/drive/MyDrive/Combined Dataset2/trai/labels'\n",
        "output_dir = '/content/drive/MyDrive/Combined Dataset2/valid/images'\n",
        "\n",
        "# Define the categories for the COCO dataset\n",
        "categories = [\n",
        "    {\"id\": 0, \"name\": \"invoice\"}\n",
        "]\n",
        "\n",
        "# Initialize the COCO dataset dictionary\n",
        "coco_dataset = {\n",
        "    \"info\": {},\n",
        "    \"licenses\": [],\n",
        "    \"categories\": categories,\n",
        "    \"images\": [],\n",
        "    \"annotations\": []\n",
        "}\n",
        "\n",
        "# Initialize a counter for image IDs\n",
        "image_id_counter = 1\n",
        "\n",
        "# Loop through the images in the input image directory\n",
        "for image_file in os.listdir(image_dir):\n",
        "    image_path = os.path.join(image_dir, image_file)\n",
        "    image = Image.open(image_path)\n",
        "    width, height = image.size\n",
        "\n",
        "    # Use the counter as the image ID\n",
        "    image_id = image_id_counter\n",
        "    image_id_counter += 1\n",
        "\n",
        "    # Add the image to the COCO dataset\n",
        "    image_dict = {\n",
        "        \"id\": image_id,\n",
        "        \"width\": width,\n",
        "        \"height\": height,\n",
        "        \"file_name\": image_file\n",
        "    }\n",
        "    coco_dataset[\"images\"].append(image_dict)\n",
        "\n",
        "    # Load the bounding box annotations for the image\n",
        "    annotation_file = os.path.join(annotation_dir, f'{image_file.split(\".jpg\")[0]}.txt')\n",
        "    with open(annotation_file) as f:\n",
        "        annotations = f.readlines()\n",
        "\n",
        "    # Loop through the annotations and add them to the COCO dataset\n",
        "    for ann in annotations:\n",
        "        parts = ann.strip().split()\n",
        "        category_id = int(float(parts[0]))  # Extract and convert category ID to int\n",
        "        x, y, w, h = map(float, parts[1:])  # Extract bounding box coordinates and convert to float\n",
        "\n",
        "        #x, y, w, h = map(float, ann.strip().split()[1:])\n",
        "        x_min, y_min = int((x - w / 2) * width), int((y - h / 2) * height)\n",
        "        x_max, y_max = int((x + w / 2) * width), int((y + h / 2) * height)\n",
        "        ann_dict = {\n",
        "            \"id\": len(coco_dataset[\"annotations\"]),\n",
        "            \"image_id\": image_id,\n",
        "            \"category_id\": category_id,\n",
        "            \"bbox\": [x_min, y_min, x_max - x_min, y_max - y_min],\n",
        "            \"area\": (x_max - x_min) * (y_max - y_min),\n",
        "            \"iscrowd\": 0\n",
        "        }\n",
        "        coco_dataset[\"annotations\"].append(ann_dict)\n",
        "\n",
        "# Save the COCO dataset to a JSON file\n",
        "with open(os.path.join(output_dir, 'annotations.json'), 'w') as f:\n",
        "    json.dump(coco_dataset, f)\n"
      ],
      "metadata": {
        "id": "Re0FPMjE6TWI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}